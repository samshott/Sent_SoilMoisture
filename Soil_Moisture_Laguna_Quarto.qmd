---
title: "Sentinel-2 Soil Moisture Data Mining Part 1"
format: html
editor: visual
Author: Sam Ericksen
Date: 3/30/2020
---

**Author:** Sam Ericksen

**Date:** 3/30/2020

```{r knitr setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
```

We are going to be pulling Sentinel-2 imagery from Google Cloud, using the Google Cloud SDK (CLI). In order for the rest of this process to work, make sure that [Google Cloud SDK](https://cloud.google.com/sdk/docs/install) is installed on your computer in the default directory.

```{r setup packages, warning=FALSE, message=FALSE}
library(sen2r) #read in sentinel-2 imagery
library(terra) #Spatial data tools
library(leaflet) #Interactive map viewer
library(sf) #for conversion between spatial formats
library(raster)
library(RColorBrewer)

check_gcloud() 
```

If you get an error about Google Cloud Initialization make sure you open a command prompt (cmd) and enter `gcloud init` .

# Create Extent

First we will need to create a feature that encompasses the area of interest, in this case - Laguna Lake in San Luis Obispo, CA. First we use an online map to get some corner coordinates and create a spatial vector. Then we make sure it's in the right place by plotting them on a leaflet map.

```{r Laguna Extent}

Laguna_Ext <- vect("POLYGON ((-120.7063985 35.2706786, 
                   -120.6881986 35.2813860, 
                   -120.6709197 35.2768445, 
                   -120.6741943 35.2647444,
                   -120.6883474 35.2544259, 
                   -120.7063985 35.2706786))")

Laguna_Ext_sf <-  sf::st_as_sf(Laguna_Ext) #sf file type needed for GeoJSON

# webmercProj <- "+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext  +no_defs"
# 
# st_crs(Laguna_Ext_sf) <- webmercProj
st_crs(Laguna_Ext_sf) <- 3857

Laguna_file_name <- "Laguna_Ext.GeoJSON" #filename for writing and using GeoJSON

write_sf(Laguna_Ext_sf, Laguna_file_name) #write it to a GeoJSON format for ingestion by sen2r()

leaflet(st_as_sf(Laguna_Ext)) %>% 
  addTiles() %>% 
  addPolygons()
```

# Download Sentinel-2 Data

`sen2r` is a package made for downloading and pre-processing Sentinel-2 data in R. The function `sen2r()` actually allows for a GUI based selection of imagery. For the sake of reproducability and automation, we will pass the parameters through the function - bypassing the graphical interface.

```{r password, echo=FALSE}
sci_user <- "gisaltmeade"
sci_pass <- "sprung-slogan-elevating"

write_scihub_login(sci_user, sci_pass)
```

```{r sen2r function, eval=FALSE}
timeframe_begin <- "2021-1-1" #change these dates to change the image download timeframe
timeframe_end <- "2022-1-1"

dir.create("temp")
tempDir <- paste0(getwd(), "/temp")

out_dir  <- tempfile(pattern = "sen2r_out_1_", tmpdir = tempDir) # output folder
safe_dir <- tempfile(pattern = "sen2r_safe_", tmpdir = tempDir)  # folder to store downloaded SAFE

out_paths <- sen2r(
  gui = FALSE,
  extent = Laguna_file_name,
  extent_name = "LagunaLake",
  timewindow = c(as.Date(timeframe_begin), as.Date(timeframe_end)),
  list_indices = c("NDMI"),
  # rm_safe = TRUE,
  # overwrite_safe = TRUE,
  max_cloud_safe = 100,
  mask_type = "cloud_and_shadow",
  max_mask = 10, #very low threshold, we dont want to sum up partial values
  path_l2a = safe_dir,
  path_out = out_dir,
  server = c("gcloud", "scihub"),
  parallel = 4,
  overwrite = TRUE
)

raster_ndmis_paths <- c(out_paths) #list of paths from raster outputs
```

```{r sen2r psuedo-Output, echo=FALSE}
# raster_ndmis_paths <- c("C:\\Users\\samer\\AppData\\Local\\Temp\\RTMPGT~1\\SEN2R_~3/NDMI/S2A2A_202101126_070_LagunaLake_NDMI_10.tif",
#                         "C:\\Users\\samer\\AppData\\Local\\Temp\\RTMPGT~1\\SEN2R_~3/NDMI/S2B2A_20210210_070_LagunaLake_NDMI_10.tif",
#                         "C:\\Users\\samer\\AppData\\Local\\Temp\\RTMPGT~1\\SEN2R_~3/NDMI/S2A2A_20210225_070_LagunaLake_NDMI_10.tif")
```

## View Raster on a Map

now we should have a character vector of paths to the downloaded Sentinel-2 Imagery. Let's Load one up to make sure it looks okay.

```{r raster map, warning=FALSE}
rast1 <- raster(raster_ndmis_paths[1]) #create a raster object from one path

rast1_pal <- colorNumeric(palette = "RdYlBu", values(rast1), na.color = "transparent", reverse = TRUE)
  
leaflet(st_as_sf(Laguna_Ext)) %>% 
  addPolygons(fillColor = "transparent") %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addRasterImage(rast1,
                 colors = rast1_pal,
                 opacity = 0.7) %>% 
  addLegend(pal = rast1_pal,
            values = values(rast1),
            title = "NDMI Values (Non-Normalized)",
            labFormat = labelFormat(transform = function(x) sort(x, decreasing = TRUE)))
```

# Working with Raster Data

Now we want to aggregate soil moisture levels in the soil throughout the given time frame. Here we are concerned with total soil moisture we will be adding up all rasters from the `sen2r()` output.

## Creating a Raster Vector

First we create a vector containing all of the SpatRaster objects. Then we use raster algebra to sum all of the rasters in the raster vector \[this may be improved with RasterStack objects\]. Then we display it over a map to make sure it still makes sense.

```{r raster list}

cumm_moisture_func <- function(path_list){
  #' read in all rasters in a list
  #' convert them to SpatRaster objects
  #' Append them to a list
  #' Return SpatRaster list
  
  raster_vect <- c()
  for (path in path_list){
    
    i_rast <- rast(path)
    
    raster_vect <- append(raster_vect, (i_rast))
  }
  
  return(raster_vect)
}

cummulative_moisture <- raster(sum(cumm_moisture_func(c(raster_ndmis_paths)), na.rm = TRUE)) #Raster algebra - add all rasters together

cumm_pal <- colorNumeric(palette = "RdYlBu",
                         domain = values(cummulative_moisture), 
                         na.color = "transparent", 
                         reverse = TRUE)


leaflet(st_as_sf(Laguna_Ext)) %>% 
  addPolygons(fillColor = "transparent") %>% 
  addProviderTiles(providers$CartoDB.Positron) %>% 
  addRasterImage(cummulative_moisture,
                colors = cumm_pal,
                opacity = 0.7,
                project = FALSE) %>% 
  addLegend(pal = cumm_pal,
            values = values(cummulative_moisture),
            title = "Cummulative NDMI Non-Normalized Values",
            labFormat = labelFormat(transform = function(x) sort(x, decreasing = TRUE)))
```

## Writing the Raster to Your Hard Drive

Now if producing the cumulative raster was your final goal you'll want to write it to your hard drive for use in other GIS applications. We'll want to give it a name that signifies the date range, so you can do this for multiple spans of times without loosing track of the data.

```{r write raster data}

daterange <- gsub(pattern = "-", 
                  paste(timeframe_begin,
                        timeframe_end,
                        sep = "_"), 
                  replacement = "")

fileName <- paste0("LagunaMoistureCumm_", daterange)

raster::writeRaster(cummulative_moisture, 
                    filename = fileName, #writes to the working directory
                    formate = writeFormats()[24]) #Geotiff indice from formats list
```
